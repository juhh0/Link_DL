{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c311676-6445-4f8c-a207-433adda63eeb",
   "metadata": {},
   "source": [
    "# hw1_1 정준호"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d516a06d-7560-42b8-8d77-f4946262e556",
   "metadata": {},
   "source": [
    "## a_tensor_initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d34f8797-793b-4110-ac4b-63213a9f20fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79cf578d-3ecc-4f7e-8afe-cc97f5ac44a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "cpu\n",
      "False\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "# torch.Tensor class\n",
    "t1 = torch.Tensor([1, 2, 3], device = 'cpu')\n",
    "print(t1.dtype)\n",
    "print(t1.device)\n",
    "print(t1.requires_grad)\n",
    "print(t1.size())\n",
    "print(t1.shape)\n",
    "\n",
    "# GPU 가지고 있을시\n",
    "# t1_cuda = t1.to(torch.device('cuda'))\n",
    "# 또는\n",
    "# t1_cuda = t1.cuda()\n",
    "t1_cpu = t1.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae99371c-fcc2-433c-b3c7-7792a5e0123b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "cpu\n",
      "False\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "#torch.tensor function\n",
    "t2 = torch.tensor([1, 2, 3], device = 'cpu')\n",
    "print(t2.dtype)\n",
    "print(t2.device)\n",
    "print(t2.requires_grad)\n",
    "print(t2.size())\n",
    "print(t2.shape)\n",
    "\n",
    "# GPU 가지고 있을시\n",
    "# t1_cuda = t1.to(torch.device('cuda'))\n",
    "# 또는\n",
    "# t1_cuda = t1.cuda()\n",
    "t1_cpu = t1.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56610432-7e5a-4a36-ba48-44a18cf37ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([]) 0\n"
     ]
    }
   ],
   "source": [
    "a1 = torch.tensor(1)\n",
    "print(a1.shape, a1.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c34594e-6822-4bc7-b04a-c19bee658c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1]) 1\n"
     ]
    }
   ],
   "source": [
    "a2 = torch.tensor([1])\n",
    "print(a2.shape, a2.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7d047f1-3498-4ac0-9846-0eb2affe3ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5]) 1\n"
     ]
    }
   ],
   "source": [
    "a3 = torch.tensor([1, 2, 3, 4, 5])\n",
    "print(a3.shape, a3.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa4f44b3-2162-4a08-aa20-fc9087f08142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1]) 2\n"
     ]
    }
   ],
   "source": [
    "a4 = torch.tensor([[1], [2], [3], [4], [5]])\n",
    "print(a4.shape, a4.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cce564fd-9c3c-4cab-b554-e257cdbc5385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2]) 2\n"
     ]
    }
   ],
   "source": [
    "a5 = torch.tensor([\n",
    "    [1, 2],\n",
    "    [3, 4],\n",
    "    [5, 6]\n",
    "])\n",
    "print(a5.shape, a5.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57a60c4f-959d-48e5-9744-501fc17ff7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2, 1]) 3\n"
     ]
    }
   ],
   "source": [
    "a6 = torch.tensor([\n",
    "    [[1], [2]],\n",
    "    [[3], [4]],\n",
    "    [[5], [6]]\n",
    "])\n",
    "print(a6.shape, a6.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efc0f52a-7785-42c4-b80e-89337da6a0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 2, 1]) 4\n"
     ]
    }
   ],
   "source": [
    "a7 = torch.tensor([\n",
    "    [[[1], [2]]],\n",
    "    [[[3], [4]]],\n",
    "    [[[5], [6]]]\n",
    "])\n",
    "print(a7.shape, a7.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68abe4fd-4cfe-41c9-827e-74e5da1042dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 2, 3]) 4\n"
     ]
    }
   ],
   "source": [
    "a8 = torch.tensor([\n",
    "    [[[1, 2, 3], [2, 3, 4]]],\n",
    "    [[[3, 1, 1], [4, 4, 5]]],\n",
    "    [[[5, 6, 2], [6, 3, 1]]]\n",
    "])\n",
    "print(a8.shape, a8.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2adc4ab2-a195-42bf-818d-cd251d1f6241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 2, 3, 1]) 5\n"
     ]
    }
   ],
   "source": [
    "a9 = torch.tensor([\n",
    "    [[[[1], [2], [3]], [[2], [3], [4]]]],\n",
    "    [[[[3], [1], [1]], [[4], [4], [5]]]],\n",
    "    [[[[5], [6], [2]], [[6], [3], [1]]]]\n",
    "])\n",
    "print(a9.shape, a9.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "572f3cd6-09d3-431a-948a-df6308bc0d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 5]) 2\n"
     ]
    }
   ],
   "source": [
    "a10 = torch.tensor([\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [1, 2, 3, 4, 5],\n",
    "])\n",
    "print(a10.shape, a10.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0adc398-344a-4f09-8e43-3c9584851867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a11 = torch.tensor([\n",
    "#     [[[1, 2, 3], [4, 5]]],\n",
    "#     [[[1, 2, 3], [4, 5]]],\n",
    "#     [[[1, 2, 3], [4, 5]]],\n",
    "#     [[[1, 2, 3], [4, 5]]],\n",
    "# ])\n",
    "# print(a11.shape, a11.ndim)\n",
    "\n",
    "# # 이 코드는 오류가 뜬다. 이유는 기대하고 있던 dim3과 다른 길이인 length 2가 왔기 때문이다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6affd8f3-bcca-4566-85a0-670a17332ccc",
   "metadata": {},
   "source": [
    "## b_tensor_initialization_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db99cbe4-b222-404f-a898-01ea4735b1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45dd1721-94db-4176-bde0-9f0cb4c2f357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n",
      "tensor([1, 2, 3])\n",
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "l1 = [1, 2, 3]\n",
    "t1 = torch.Tensor(l1)\n",
    "\n",
    "l2 = [1, 2, 3]\n",
    "t2 = torch.tensor(l2)\n",
    "\n",
    "l3 = [1, 2, 3]\n",
    "t3 = torch.as_tensor(l3)   # as_tensor는 가능하면 공유 필요하면 복사, \n",
    "                           # 리스트는 버퍼공유 불가이므로 결국 복사 발생\n",
    "\n",
    "l1[0] = 100\n",
    "l2[0] = 100\n",
    "l3[0] = 100\n",
    "\n",
    "print(t1)\n",
    "print(t2)\n",
    "print(t3)\n",
    "\n",
    "# 고찰 결과\n",
    "# 파이썬의 list는 ndarray와 다르게 메모리 버퍼를 적접 공유할 수 없다. \n",
    "# 따라서 리스트를 넘겨주면, PyTorch는 내부적으로 리스트 내용을 복사해서 새로운 텐서를 \n",
    "# 만들기 때문에 리스트의 값을 변경해도 tensor에는 반영이 안되는 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbed19ae-c093-4f6d-a02a-05ce5f92426a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n",
      "tensor([1, 2, 3], dtype=torch.int32)\n",
      "tensor([100,   2,   3], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "l4 = np.array([1, 2, 3])\n",
    "t4 = torch.Tensor(l4)\n",
    "\n",
    "l5 = np.array([1, 2, 3])\n",
    "t5 = torch.tensor(l5)\n",
    "\n",
    "l6 = np.array([1, 2, 3])\n",
    "t6 = torch.as_tensor(l6)\n",
    "\n",
    "l4[0] = 100\n",
    "l5[0] = 100\n",
    "l6[0] = 100\n",
    "\n",
    "print(t4)\n",
    "print(t5)\n",
    "print(t6)\n",
    "\n",
    "# 고찰 결과\n",
    "# torch.Tensor와 torch.tensor는 항상 복사한다.\n",
    "# torch.as_tensor는 가능하면 공유, 필요하면 복사를 한다\n",
    "# torch.as_tensor와 비슷한 함수로는 torch.from_numpy(ndarray)가있는데 이는 무조건 메모리를 공유한다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082e0475-ec05-403d-85db-8e2fd54d0a95",
   "metadata": {},
   "source": [
    "## c_tensor_initialization_constant_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0369f1b-0d93-4399-8161-555424fee19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "tensor([1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.ones(size=(5,))  # or torch.ones(5)\n",
    "# 콤마가 들어가는 이유?\n",
    "# => size는 정수 튜플이나 정수 리스트가 들어가야함. 따라서 5, 로 길이가 5인 1차원 텐서를 만든다 \n",
    "\n",
    "t1_like = torch.ones_like(input=t1) # ones_like(t1)은 t1과 shape이 같은 1로 이루어진 텐서를 만든다\n",
    "print(t1)\n",
    "print(t1_like)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "465b40d4-fbf9-41e5-873f-dbe749fbfa26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "t2 = torch.zeros(6)     # or torch.zeros(size=(6,))\n",
    "                        # 콤마가 들어가는 이유?\n",
    "                        # => size는 정수 튜플이나 정수 리스트가 들어가야함. 따라서 5, 로 길이가 5인 1차원 텐서를 만든다\n",
    "\n",
    "t2_like = torch.zeros_like(t2)   # t2와 같은 shape의 0으로 구성된 텐서를 만든다\n",
    "print(t2)\n",
    "print(t2_like)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd6c43fa-cb0c-4a7d-88ab-e9dda8e2b0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0.])\n",
      "tensor([-4.2653e-14,  1.5975e-42,  0.0000e+00,  0.0000e+00])\n"
     ]
    }
   ],
   "source": [
    "t3 = torch.empty(4)\n",
    "t3_like = torch.empty_like(t3) # t3와 같은 shape의 비어있는 텐서를 만든다\n",
    "print(t3)\n",
    "print(t3_like)\n",
    "\n",
    "# 이 코드는 실행할 때 마다 다른 값이나옴\n",
    "# 그 이유는 empty는 비어있는 텐서를 만드는데 즉, 메모리 공간만 잡아놓고, 안에 든 값을 초기화 하지 않는다\n",
    "# 따라서 잡아놓은 메모리에 남아있던 쓰레기 값이 들어가게 되어 출력결과가 다르게 보일 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2a6de18-1e25-4562-8c59-fd644b19c049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "t4 = torch.eye(3)\n",
    "print(t4)\n",
    "\n",
    "# torch.eye(n)은 n x n의 대각성분이 1인 텐서를 만든다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07156446-116f-488b-9217-16b778dd3c98",
   "metadata": {},
   "source": [
    "## d_tensor_initialization_random_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "119dee7c-13a7-4a2c-a2fb-a83346bbbc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9f3f47b-150f-459d-bd7b-6fca7413ba7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[15, 13]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.randint(low=10, high=20, size=(1, 2))\n",
    "print(t1)\n",
    "\n",
    "# torch.randint(low, high, size)\n",
    "# [low, high) 으로 low이상 high미만으로 이루어진 정수를 size에 맞는 텐서를 반환한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c268982-b575-452a-a2d7-53d2a77d028d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0713, 0.3694, 0.2862]])\n"
     ]
    }
   ],
   "source": [
    "t2 = torch.rand(size=(1, 3))\n",
    "print(t2)\n",
    "\n",
    "# torch.rand(size)\n",
    "# 이것은 균등분포(uniform dstribution)를 따르고 구간 0이상 1미만에서 난수 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a82ede20-3df1-4043-968a-e0c682383e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7373,  0.1835,  0.4980]])\n"
     ]
    }
   ],
   "source": [
    "t3 = torch.randn(size=(1, 3))\n",
    "print(t3)\n",
    "\n",
    "# torch.randn(size)\n",
    "# 표준 정규분포(Standard Normal distribution)에서 난수 생성\n",
    "# 평균 = 0, 표준편차 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b7ae537-41c6-48e1-9b90-1ac4caf23c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[11.3764,  8.7332],\n",
      "        [ 9.9501, 10.0081],\n",
      "        [11.4023,  9.1393]])\n"
     ]
    }
   ],
   "source": [
    "t4 = torch.normal(mean=10.0, std=1.0, size=(3, 2))\n",
    "print(t4)\n",
    "\n",
    "# torch.normal(mean, std, size)\n",
    "# 일반 정규분포(normal distribution) 직접 분포도를 지정\n",
    "# 위 예제는 평균 10, 편차 1을 따른다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4664404a-bf53-493b-90b6-84bda5cf3d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 2.5000, 5.0000])\n"
     ]
    }
   ],
   "source": [
    "t5 = torch.linspace(start=0.0, end=5.0, steps=3)\n",
    "print(t5)\n",
    "\n",
    "# torch.linspace(start, end, steps)\n",
    "# 처음과 끝이 각각 start와 end값으로 이루어져있고 steps값만큼 길이를 만든다. 간격은알아서 조정된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a45ce10d-68df-4610-a82d-4a1f109d851e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "t6 = torch.arange(5)\n",
    "print(t6)\n",
    "\n",
    "# torch.arange(n)\n",
    "# 0부터 n-1까지의 정수를 순차적으로 넣어 텐서를 만든다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d84d3fc6-509c-457a-b787-fc10fdedd2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3126, 0.3791, 0.3087],\n",
      "        [0.0736, 0.4216, 0.0691]])\n",
      "tensor([[0.2332, 0.4047, 0.2162],\n",
      "        [0.9927, 0.4128, 0.5938]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1729)\n",
    "random1 = torch.rand(2, 3)\n",
    "print(random1)\n",
    "\n",
    "random2 = torch.rand(2, 3)\n",
    "print(random2)\n",
    "\n",
    "# 랜덤으로 나오는 seed를 고정한다\n",
    "# 즉, 일관된 랜덤 seed를 얻을 수 있어 실험을 할때 등등 일관적으로 훈련할 수 있다\n",
    "# 개인적으로 찾아본결과 seed값은 0<=seed<2**32(약 42억)의 정수를 넣으면 되는것으로 알고 있다.\n",
    "# 즉 seed는 약 42억개의 방의 열쇠와 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a2efa270-50f9-497d-b540-5c25f5f5315c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3126, 0.3791, 0.3087],\n",
      "        [0.0736, 0.4216, 0.0691]])\n",
      "tensor([[0.2332, 0.4047, 0.2162],\n",
      "        [0.9927, 0.4128, 0.5938]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1729)\n",
    "random3 = torch.rand(2, 3)\n",
    "print(random3)\n",
    "\n",
    "random4 = torch.rand(2, 3)\n",
    "print(random4)\n",
    "\n",
    "# 위 셀의 결과와 같은 것을 볼 수 있다. 즉, seed값이 같으면 어디에서나 같은 방식으로 동작하는 코드이므로\n",
    "# 일관된 결과를 얻을 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cce572-6b23-4c1c-815a-fdab3557a26a",
   "metadata": {},
   "source": [
    "## e_tensor_type_conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b613dabd-023a-4547-876c-30cad20be48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "torch.float32\n",
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1]], dtype=torch.int16)\n",
      "tensor([[10.0160,  9.3871,  7.4563],\n",
      "        [17.3151, 14.5980,  6.0404]], dtype=torch.float64)\n",
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones((2, 3))\n",
    "print(a)  # b와 같이 dtype이 같이 출력되는지 확인하기 위한 코드 추가\n",
    "print(a.dtype)\n",
    "\n",
    "b = torch.ones((2, 3), dtype=torch.int16)  # dtype 매개변수를 이용하여 데이터 타입을 지정한다\n",
    "print(b)\n",
    "\n",
    "torch.manual_seed(1729)  # (추가)20.이 텐서 모든값에 대해서 곱해지는지 밑에서 확인하기위해 seed를 고정\n",
    "c = torch.rand((2, 3), dtype=torch.float64) * 20.  # 모든 값에 대해서 20이 곱해진다\n",
    "print(c)\n",
    "\n",
    "d = b.to(torch.int32)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "720de9b9-eb52-47b3-8f98-58edbb2c94be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5008, 0.4694, 0.3728],\n",
      "        [0.8658, 0.7299, 0.3020]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# (추가)\n",
    "# 이 코드는 위의 c에 해당하는 코드가 20이 전체 값에 대해서 곱해지는지 확인하기위해 seed를 지정하여 비교할 수 있도록 코드를 작성함\n",
    "torch.manual_seed(1729)\n",
    "print(torch.rand((2, 3), dtype=torch.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5057d567-ed83-4595-a559-25c1bfd74bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]], dtype=torch.float64)\n",
      "----------------------------------------\n",
      "tensor([[1, 2]], dtype=torch.int16)\n"
     ]
    }
   ],
   "source": [
    "# (추가)\n",
    "# 교수님의 코드는 double_d와 short_e에 대하여 적혀있지만 각각의 텐서를 확인하기 위해 print구문을 추가하였다\n",
    "\n",
    "double_d = torch.ones(10, 2, dtype=torch.double)  # torch.double은 torch.float64와 같음 64비트의 부동소수점 지원\n",
    "short_e = torch.tensor([[1, 2]], dtype=torch.short)  # torch.short는 torch.int16와 같음 \n",
    "\n",
    "print(double_d)\n",
    "print(\"-\" *40)\n",
    "print(short_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "33a17e0f-4e00-4101-80f9-ec2cc5b97d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]], dtype=torch.float64)\n",
      "----------------------------------------\n",
      "tensor([[1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1]], dtype=torch.int16)\n"
     ]
    }
   ],
   "source": [
    "double_d = torch.zeros(10, 2).double()\n",
    "short_e = torch.ones(10, 2).short()\n",
    "\n",
    "print(double_d)\n",
    "print(\"-\" *40)\n",
    "print(short_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "01dcbf77-1db1-484f-85fb-d5ac03478251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]], dtype=torch.float64)\n",
      "----------------------------------------\n",
      "tensor([[1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1]], dtype=torch.int16)\n"
     ]
    }
   ],
   "source": [
    "double_d = torch.zeros(10, 2).to(torch.double)\n",
    "short_e = torch.ones(10, 2).to(dtype=torch.short)\n",
    "\n",
    "print(double_d)\n",
    "print(\"-\" *40)\n",
    "print(short_e)\n",
    "\n",
    "# 고찰\n",
    "# PyTorch에서 .to()연산자는 텐서의 속성을 바꿀 때 사용한다\n",
    "# 예를 들어 dtype, device, memory format을 바꿀때 사용한다 각 예제는 다음과 같다\n",
    "# .to(torch.double)\n",
    "# .to(\"cuda\")\n",
    "# 둘다 사용할 경우 .to(dtype=torch.double, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aae76c78-1269-4151-af67-e0161365e232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]], dtype=torch.float64)\n",
      "----------------------------------------\n",
      "tensor([[1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1]], dtype=torch.int16)\n"
     ]
    }
   ],
   "source": [
    "double_d = torch.zeros(10, 2).type(torch.double)\n",
    "short_e = torch.ones(10, 2).type(dtype=torch.short)\n",
    "\n",
    "print(double_d)\n",
    "print(\"-\" *40)\n",
    "print(short_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b3234c80-fe92-4d76-b6e6-0386472ad2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float64\n",
      "torch.int16\n"
     ]
    }
   ],
   "source": [
    "print(double_d.dtype)\n",
    "print(short_e.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eeacd8fb-cad8-43b7-ab54-72d339f0a81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "double_f = torch.rand(5, dtype=torch.double)\n",
    "short_g = double_f.to(torch.short)\n",
    "print((double_f * short_g).dtype)\n",
    "# memory format이 다른 텐서를 곱하는 경우 memory format이 큰 텐서의 dtype으로 지정됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c60d3eff-c7f4-4b01-b8aa-b9850f8f11a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 고찰\n",
    "# 텐서의 타입을 바꾸는 방법은 다양하게 존재하며 편한것을 사용하면 될듯하다\n",
    "# 개인적으론 .to()연산자를 사용하는것이 직관적이라 좋아하나 사람들마다 다 사용하는 방식이 다르므로\n",
    "# 모든 방법을 익혀놓는것이 중요할 듯 하다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028975a6-bdc8-49d0-bce7-1a1760950bd7",
   "metadata": {},
   "source": [
    "## f_tensor_operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7b720df9-97bd-4137-a3d3-ded594ce1ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9f254e9b-ea3c-4f73-91d0-1684f3e0eb01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.]])\n",
      "tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.ones(size=(2, 3))\n",
    "t2 = torch.ones(size=(2, 3))\n",
    "t3 = torch.add(t1, t2)\n",
    "t4 = t1 + t2\n",
    "print(t3)\n",
    "print(t4)\n",
    "# add를 하고 싶을때 두가지방법이 존재\n",
    "# 1. torch.add()함수 사용\n",
    "# 2. t1 + t2 그냥 더하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ebc7985b-a310-42a8-98ac-e12b61d5c8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (추가)\n",
    "# add하고자 하는 텐서의 shape이 맞지 않으면 어떻게 될까 궁금하여 shape을 다르게 해봄\n",
    "# 생각했던대로 error가 떳고 shape맞을 경우에만 add가능함\n",
    "# 연습코드에 지장이 없도록 주석리리\n",
    "\n",
    "# t1 = torch.ones(size=(2, 3))\n",
    "# t2 = torch.ones(size=(2, 2))\n",
    "# t3 = torch.add(t1, t2)\n",
    "# t4 = t1 + t2\n",
    "# print(t3)\n",
    "# print(t4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4123e261-3fd5-4286-9ea2-e0211a1e57f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "t5 = torch.sub(t1, t2)\n",
    "t6 = t1 - t2\n",
    "print(t5)\n",
    "print(t6)\n",
    "# subtract 하고 싶을때 두가지방법이 존재\n",
    "# 1. torch.sub()함수 사용\n",
    "# 2. t1 - t2 그냥 기기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b5997dbe-08b4-45c4-9f4b-017598553474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "t7 = torch.mul(t1, t2)\n",
    "t8 = t1 * t2\n",
    "print(t7)\n",
    "print(t8)\n",
    "# 곱하고 싶을때 두가지방법이 존재\n",
    "# 1. torch.mul()함수 사용\n",
    "# 2. t1 * t2 그냥 곱하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c0ea5d9d-4d90-48e3-8073-c0ae75d069b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "t9 = torch.div(t1, t2)\n",
    "t10 = t1 / t2\n",
    "print(t9)\n",
    "print(t10)\n",
    "# 나누고 싶을때 두가지방법이 존재\n",
    "# 1. torch.div()함수 사용\n",
    "# 2. t1 / t2 그냥 나누기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d2ddee-241d-4e64-9cb9-69e5ce44587b",
   "metadata": {},
   "source": [
    "## g_tensor_operations_mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "44195526-c2d1-4b8a-89cb-1326573e687a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5d30d883-1f38-4c7d-81a7-d5d17c38f814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7) torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.dot(                  # torch.dot은 1차원 텐서만 허용. 길이도 같아야함. 내적을 계산함\n",
    "    torch.tensor([2, 3]), torch.tensor([2, 1])\n",
    ")\n",
    "print(t1, t1.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "00488a83-dfcb-4e87-a82b-7e0676b380c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1766, -0.3342],\n",
      "        [-3.0611, -0.5943]]) torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "t2 = torch.randn(2, 3)\n",
    "t3 = torch.randn(3, 2)\n",
    "t4 = torch.mm(t2, t3)       # 행렬을 계산하는 함수 즉, 결과가 2 x 2텐서로 나옴\n",
    "print(t4, t4.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a8e5fed5-5844-4315-9354-00edfdcb0620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "t5 = torch.randn(10, 3, 4)\n",
    "t6 = torch.randn(10, 4, 5)\n",
    "t7 = torch.bmm(t5, t6)\n",
    "print(t7.size())\n",
    "# 배치단위로 행렬곱을 수행하는 예시이다\n",
    "# 배치는 10이고 각각 3x4, 4x5 행렬을 가지고 있어서 연산수행한다\n",
    "# torch.bmm()은 3차원 텐서만 지원한다\n",
    "# 4차원 이상을 하고자 하면 torch.matmul() 또는 @연산자를 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b64aaa3-b716-4a96-a28e-e85531d4ba0c",
   "metadata": {},
   "source": [
    "## h_tensor_operations_matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c3c55846-57c4-4259-a6e3-3dcbe9cb1ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1eeeeaa4-4bed-4ed3-b224-dc788ecf9e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.randn(3)\n",
    "t2 = torch.randn(3)\n",
    "print(torch.matmul(t1, t2).size()) \n",
    "#matmul은 모든차원에 적용가능하고 자동적으로 브로드캐스팅 적용한다\n",
    "\n",
    "# (추가) 브로드 캐스팅이란? (원소별 연산임 : 산술연산, 비교연산, 논리연산, 수학함수 등)\n",
    "# => 크기가 다른 텐서끼리 연산할 때, 작은 텐서의 크기를 자동으로 확장해서 연산해주는 규칙\n",
    "# 1. 같으면 그대로 연산 가능\n",
    "# 2. rank가 더 작은 텐서의 앞쪽에 1을 채워넣고 비교하면서 텐서 확장\n",
    "# 3. 둘 다 다르고 1도 아니면 에러발생\n",
    "####주의 : 행렬 곱셈 : 브로드캐스팅은 마지막 두 차원을 행렬로 처리, 나머지 차원만 브로드캐스팅됨\n",
    "####주의 : 행렬 전용 연산(torch.mm, torch.bmm) : 입력 차원이 딱 정해져 있어서 브로드캐스팅 불가\n",
    "\n",
    "# (추가) matmul의 규칙\n",
    "# 1D x 1D => 내적, 스칼라\n",
    "# 2D x 2D => 행렬 곱(2D)\n",
    "# 2D x 1D => 행렬-벡터 곱 (1D 벡터)\n",
    "# 1D x 2D => 벡터-행렬 곱 (1D 벡터)\n",
    "# N차원 => 마지막 두 축은 행렬 곱, 앞 축들은 브로드캐스팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f8f11860-f7f0-4344-94f2-8115f7c5e0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "t3 = torch.randn(3, 4)\n",
    "t4 = torch.randn(4)\n",
    "print(torch.matmul(t3, t4).size())\n",
    "\n",
    "# 위의 규칙을 따르면 2Dx1D이므로 3이 된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3f973310-6dfe-4326-9e3b-ff07ccab4a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3])\n"
     ]
    }
   ],
   "source": [
    "t5 = torch.randn(10, 3, 4)\n",
    "t6 = torch.randn(4)\n",
    "print(torch.matmul(t5, t6).size())\n",
    "\n",
    "# 위의 규칙을 따르면 브로드캐스팅에 의해 t6는 (10, 1, 4)가 되고 총 계산결과 size는 (10, 3)이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dc42c9d8-5a45-47af-952f-414e5fd5cd35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "t7 = torch.randn(10, 3, 4)\n",
    "t8 = torch.randn(10, 4, 5)\n",
    "print(torch.matmul(t7, t8).size())\n",
    "\n",
    "# 이 예시는 batch와 행렬 곱의 size가 맞아 떨어지므로 계산이 온전하게 잘 된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e2c89d42-dbc5-4217-8127-e42b48558ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "t9 = torch.randn(10, 3, 4)\n",
    "t10 = torch.randn(4, 5)\n",
    "print(torch.matmul(t9, t10).size())\n",
    "\n",
    "# t10은 배치가 없으므로 브로드캐스팅에 의해 size가 (10, 4, 5)로 증가한다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936c06be-8b8c-4818-a844-7caa30ec8c48",
   "metadata": {},
   "source": [
    "## i_tensor_broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6dda6480-4ac9-4ffa-b8d6-b0cacbcc1225",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "63adbaf9-905e-4595-8e97-ba9d397cc2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 4., 6.])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.tensor([1.0, 2.0, 3.0])\n",
    "t2 = 2.0\n",
    "print(t1 * t2)\n",
    "\n",
    "# 자동으로 t2를 브로드캐스팅할 수 있는 텐서로 변환하여 곱을 수행함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a4b31d6f-4a7f-4428-86f1-3a4e2ec5504e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-4, -4],\n",
      "        [-2, -1],\n",
      "        [ 6,  5]])\n"
     ]
    }
   ],
   "source": [
    "t3 = torch.tensor([[0, 1], [2, 4], [10, 10]])\n",
    "t4 = torch.tensor([4, 5])\n",
    "print(t3 - t4)\n",
    "\n",
    "# 자동으로 t4를 브로드캐스팅할 수 있는 텐서로 변환하여 sub을 수행한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "841bcd86-c8d5-43be-8c55-b29a627f7165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 4.],\n",
      "        [5., 6.]])\n",
      "tensor([[-1.,  0.],\n",
      "        [ 1.,  2.]])\n",
      "tensor([[2., 4.],\n",
      "        [6., 8.]])\n",
      "tensor([[0.5000, 1.0000],\n",
      "        [1.5000, 2.0000]])\n"
     ]
    }
   ],
   "source": [
    "t5 = torch.tensor([[1., 2.], [3., 4.]])\n",
    "print(t5 + 2.0)\n",
    "print(t5 - 2.0)\n",
    "print(t5 * 2.0)\n",
    "print(t5 / 2.0)\n",
    "\n",
    "# 마찬가지로 2.0을 t5에 대해 연산을 할 수 있도록 브로드캐스티을 진행하여 연산을 수행한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "294380fb-4981-4fb2-af84-f451f695c80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    return x / 255\n",
    "\n",
    "t6 = torch.randn(3, 28, 28)\n",
    "print(normalize(t6).size())\n",
    "\n",
    "# 브로드캐스팅 규칙에 의해 normalize(X)의 연산인 x / 255를 t6의 모든 값에 대해서 수행한다.\n",
    "# 브로드캐스팅을 활용한 텐서연산이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "997c9fdb-c88f-461c-91fb-94d45d9df4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4, 3],\n",
      "        [3, 4]])\n",
      "tensor([[6, 7],\n",
      "        [2, 5]])\n",
      "tensor([[8, 6],\n",
      "        [5, 3]])\n",
      "tensor([[ 8,  9],\n",
      "        [ 7, 10]])\n"
     ]
    }
   ],
   "source": [
    "t7 = torch.tensor([[1, 2], [0, 3]])\n",
    "t8 = torch.tensor([[3, 1]])\n",
    "t9 = torch.tensor([[5], [2]])\n",
    "t10 = torch.tensor([7])\n",
    "print(t7 + t8)\n",
    "print(t7 + t9)\n",
    "print(t8 + t9)   # 각각 [[3, 1], [3, 1]]  // [[5, 5], [2, 2]] 로 확장된다\n",
    "print(t7 + t10)\n",
    "\n",
    "# 브로드 캐스팅으로 사이즈를 맞춰서 연산을 수행한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5a9c2d14-e004-4ef2-aaa6-184d1c87fc61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "t11 = torch.ones(4, 3, 2)\n",
    "t12 = t11 * torch.rand(3, 2)\n",
    "print(t12.shape)\n",
    "\n",
    "# 브로드캐스팅에 의해 t11이 확장되어  연산수행이 가능해진다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2ba936ba-ffc7-4054-ab2b-745c9c6c1cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "t13 = torch.ones(4, 3, 2)\n",
    "t14 = t13 * torch.rand(3, 1)\n",
    "print(t14.shape)\n",
    "\n",
    "# torch.rand(3, 1)의 사이즈가 확장되어 (4, 3, 2)가 된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "53d23fe9-0bc4-40b1-b41e-cb43b4ab5282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "t15 = torch.ones(4, 3, 2)\n",
    "t16 = t15 * torch.rand(1, 2)\n",
    "print(t16.shape)\n",
    "\n",
    "# torch.rand(1, 2)의 사이즈가 확자되어 (4, 3, 2)가 된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "32a5e51d-6653-4148-84c4-45942933fb18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "t17 = torch.ones(5, 3, 4, 1)\n",
    "t18 = torch.rand(3, 1, 1)\n",
    "print((t17 + t18).size())\n",
    "\n",
    "# torch.rand(3, 1, 1)의 사이즈가 확장되어 (5, 3, 4, 1)이 된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3cee56af-92c9-45e7-973f-9808c2e31ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "t19 = torch.empty(5, 1, 4, 1)\n",
    "t20 = torch.empty(3, 1, 1)\n",
    "print((t19 + t20).size())\n",
    "\n",
    "# 먼저 t20이 확장되어 t20.shape이 (5, 3, 1, 1)이 된다\n",
    "# 그 후 서로의 크기에 맞게 조정되어 (5, 3, 4, 1)이 된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a3a7a791-9007-48da-86b8-3f0dc3a1a4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 7])\n"
     ]
    }
   ],
   "source": [
    "t21 = torch.empty(1)\n",
    "t22 = torch.empty(3, 1, 7)\n",
    "print((t21 + t22).size())\n",
    "\n",
    "# torch.empty 역시 브로드캐스팅에 의해 확장되어 (3, 1, 7)이 된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ab1cc13f-e506-4a92-afdc-2b096e0a049a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "t23 = torch.ones(3, 3, 3)\n",
    "t24 = torch.ones(3, 1, 3)\n",
    "print((t23 + t24).size())\n",
    "\n",
    "# 브로드캐스팅에 의해 t24의 shape이 (3, 3, 3)이 된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fedade5a-12d9-4e93-bb00-378a4b4e6fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t25 = torch.empty(5, 2, 4, 1)\n",
    "# t26 = torch.empty(3, 1, 1)\n",
    "# print((t25 + t26).size())\n",
    "\n",
    "# # 브로드캐스팅은 크기를 맞출려는 차원의 값이 1이어야 연산하고자하는 텐서의 크기에 맞출 수 있다\n",
    "# # 하지만 이는 2와 3이므로 브로드캐스팅 규칙에 맞지않으므로 오류가 뜬다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cf0fd7ec-2448-46c9-91a9-e452ef094020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 5., 5., 5.])\n"
     ]
    }
   ],
   "source": [
    "t27 = torch.ones(4) * 5\n",
    "print(t27)\n",
    "\n",
    "# 브로드캐스팅에 의해 5가 브로드캐스팅되어 연산이 가능해진다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "96256622-6a91-4846-807b-66bdd9864ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([25., 25., 25., 25.])\n"
     ]
    }
   ],
   "source": [
    "t28 = torch.pow(t27, 2)\n",
    "print(t28)\n",
    "\n",
    "# 거듭제곱도 브로드캐스팅 가능하므로 2가 확장되어 연산을 수행한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5f9078ad-4f83-49b7-a7ee-0c673d75fdcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  1.,   4.,  27., 256.])\n"
     ]
    }
   ],
   "source": [
    "exp = torch.arange(1., 5.)\n",
    "a = torch.arange(1., 5.)\n",
    "t29 = torch.pow(a, exp)\n",
    "print(t29)\n",
    "\n",
    "# 연산하고자 하는 텐서의 shape이 같으므로 1, 2, 3, 5를 각각 1제곱 2제곱 3제곱 4제곱 5제곱을 하여 결과 도출한다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f8d45a-6460-4d5b-a7df-11cb96dd6fe3",
   "metadata": {},
   "source": [
    "## j_tensor_indexing_slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "79155360-d3cc-4aa2-952c-f56f52d993a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d565c103-c008-4ffc-84c1-227e0c7492ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 6, 7, 8, 9])\n",
      "tensor([ 1,  6, 11])\n",
      "tensor(7)\n",
      "tensor([ 4,  9, 14])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(\n",
    "    [[0, 1, 2, 3, 4],\n",
    "     [5, 6, 7, 8, 9],\n",
    "     [10, 11, 12, 13, 14]]\n",
    ")\n",
    "\n",
    "print(x[1])     # 원소는 이차원안의 리스트들이므로 인덱스 1번에 해당하는 [5, 6, 7, 8, 9]\n",
    "print(x[:, 1])  # x[a, b]라 했을때 a는이차원안의 리스트, b는 해당 리스트안의 원소를 말한다.\n",
    "                # 즉, 이차원의 모든원소에 대해서 1번인덱스를 추출해라 라는 뜻이다.\n",
    "print(x[1, 2])\n",
    "print(x[:, -1]) # -1은 뒤에서 첫번째 원소를 가리키므로 모든원소에 대해서 맨 뒤의 원소를 추출하라는 뜻이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bad591ce-2434-4e25-8910-329d967ec201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5,  6,  7,  8,  9],\n",
      "        [10, 11, 12, 13, 14]])\n",
      "tensor([[ 8,  9],\n",
      "        [13, 14]])\n"
     ]
    }
   ],
   "source": [
    "print(x[1:])       # 1번인덱스부터 전체를 출력하라는 뜻\n",
    "print(x[1:, 3:])   # 1번인덱스부터 전체를 추출하고 해당 원소리스트에서도 3번인덱스부터 추출하라는 뜻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cb069ccc-eb17-43e3-a2f2-5e3ef0c31222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.zeros((6, 6))\n",
    "y[1:4, 2] = 1\n",
    "print(y)   # 이차원에 대해서 1, 2, 3번 리스트 중에 2번 인덱스의 값만 1로 변경한다는 뜻이다\n",
    "\n",
    "print(y[1:4, 1:4])   # 이차원에 대해서 1, 2, 3번 리스트에서 각각1, 2, 3번 인덱스를 추출한다는 뜻이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5458437c-8e84-4277-980a-44eed901fc79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 4],\n",
      "        [2, 3, 4, 5]])\n",
      "tensor([[3, 4],\n",
      "        [6, 7]])\n",
      "tensor([[2, 3, 4],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n",
      "tensor([[1, 2, 3, 4],\n",
      "        [2, 0, 0, 5],\n",
      "        [5, 0, 0, 8]])\n"
     ]
    }
   ],
   "source": [
    "z = torch.tensor(\n",
    "    [[1, 2, 3, 4],\n",
    "     [2, 3, 4, 5],\n",
    "     [5, 6, 7, 8]]\n",
    ")\n",
    "print(z[:2])\n",
    "print(z[1:, 1:3])\n",
    "print(z[:, 1:])\n",
    "\n",
    "z[1:, 1:3] = 0\n",
    "print(z)\n",
    "\n",
    "# 위에서 설명했다시피 인덱스 규칙에 맞게 각각 출력하고 값을 변경하는 작업을 하는 코드이다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53190be-b420-4a85-ae32-eca3d328cb40",
   "metadata": {},
   "source": [
    "## k_tensor_reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5d1eeca1-db46-4f2f-8a01-f933f336e024",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d2cbbe82-008b-4c8a-abc3-295792a8ad3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n",
      "tensor([[1, 2, 3, 4, 5, 6]])\n",
      "tensor([[0, 0, 3],\n",
      "        [4, 5, 6]])\n",
      "tensor([[5, 5, 5],\n",
      "        [5, 5, 5]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "t2 = t1.view(3, 2)    \n",
    "# 새로운 텐서를 만들지 않고 원래 데이터를 바라보는 새로운 뷰를 만듬.\n",
    "# 즉, view()로 만든 텐서를 바꾸면 원본에도 영향이 감\n",
    "t3 = t1.reshape(1, 6)\n",
    "# contiguous하면 view() 처럼 동작\n",
    "# contiguous하지 않으면 새로운 복사본을 만들어서 동작\n",
    "print(t2)\n",
    "print(t3)\n",
    "\n",
    "# (추가) 각각 t2와 t3를 바꾸었을때 t1이 바뀌는지 확인하기 위한 코드 추가\n",
    "t2[0] = torch.tensor([0, 0])\n",
    "print(t1)\n",
    "t3[0] = torch.tensor(5)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "02c48ee7-b97a-4749-8bd4-a58b49547a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2, 3],\n",
      "        [4, 5, 6, 7]])\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n"
     ]
    }
   ],
   "source": [
    "t4 = torch.arange(8).view(2, 4) # 길이가 8인 0부터 7인 텐서를 주어진 사이즈에 맞게 변환\n",
    "t5 = torch.arange(6).view(2, 3) # 길이가 6인 0부터 5인 텐서를 주어진 사이즈에 맞게 변환\n",
    "print(t4)\n",
    "print(t5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0de87e58-6a79-40b6-9c2e-01b10b84ea29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3]])\n",
      "torch.Size([1, 3, 1])\n",
      "torch.Size([3])\n",
      "torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "t6 = torch.tensor([[[1], [2], [3]]])\n",
    "t7 = t6.squeeze()  # 1인 차원 모두 제거\n",
    "t8 = t6.squeeze(0) # dim 0의 차원 거거\n",
    "print(t7)\n",
    "print(t8)\n",
    "\n",
    "# (추가) t6, t7, t8의 shape확인을 위해 코드 추가\n",
    "print(t6.shape)\n",
    "print(t7.shape)\n",
    "print(t8.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "73b99057-2a0a-44d2-8149-967e29e3f259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1],\n",
      "        [2],\n",
      "        [3]])\n",
      "torch.Size([3])\n",
      "torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "t9 = torch.tensor([1, 2, 3])\n",
    "t10 = t9.unsqueeze(1) # 1차원의 위치에 차원 추가 (1로 추가한다)\n",
    "print(t10)\n",
    "\n",
    "# (추가) shape확인을 위한 코드 추가\n",
    "print(t9.shape)\n",
    "print(t10.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "abe1c955-c6f4-4437-bf19-d110fe04d98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]]) torch.Size([2, 1, 3])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([2, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "t11 = torch.tensor(\n",
    "    [[1, 2, 3],\n",
    "     [4, 5, 6]]\n",
    ")\n",
    "t12 = t11.unsqueeze(1) # 1차원의 위치에 차원 추가 (1로 추가한다)\n",
    "print(t11, t12.shape)\n",
    "\n",
    "# (추가) shape확인을 위한 코드 추가\n",
    "print(t11.shape)\n",
    "print(t12.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "61a0f30b-8c8f-48cb-852e-b65382883239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5, 6])\n"
     ]
    }
   ],
   "source": [
    "t13 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "t14 = t13.flatten()  # flatten()은 여러차원을 1차원으로 펴서 벡터로 만듬\n",
    "print(t14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "17b14bf3-2cd2-4b06-b2d6-c794d80e2e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5, 6, 7, 8])\n",
      "tensor([[1, 2, 3, 4],\n",
      "        [5, 6, 7, 8]])\n"
     ]
    }
   ],
   "source": [
    "t15 = torch.tensor([[[1, 2],\n",
    "                     [3, 4]],\n",
    "                     [[5, 6],\n",
    "                      [7, 8]]])\n",
    "t16 = torch.flatten(t15)             # t15.flatten()과 같은 결과\n",
    "t17 = torch.flatten(t15, start_dim=1)  # 0번쨰 차원은 그대로 고 1번째 차원부터 끝까지 flatten함\n",
    "\n",
    "print(t16)\n",
    "print(t17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b4580f73-71ef-4ffd-82db-7fa40b52122d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 5])\n",
      "torch.Size([5, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "t18 = torch.randn(2, 3, 5)\n",
    "print(t18.shape)\n",
    "print(torch.permute(t18, (2, 0, 1)).size())   # permute는 차원을 바꾸는 작업이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "372ba758-1ca0-4151-853d-6461f08b6adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n"
     ]
    }
   ],
   "source": [
    "t19 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "t20 = torch.permute(t19, dims=(0, 1))\n",
    "t21 = torch.permute(t19, dims=(1, 0))  # 행과 열을 서로 바꾼다. 즉 행렬 전치와 같다.\n",
    "print(t20)\n",
    "print(t21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f962baca-3378-4bfe-aae6-3400c7a23011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n"
     ]
    }
   ],
   "source": [
    "t22 = torch.transpose(t19, 0, 1) \n",
    "# 모든 차원 텐서에서 사용 가능\n",
    "# 임의의 두 차원을 서로 바꾼다.\n",
    "# 원하는 아무 두 축을 바꿀 수 있다.\n",
    "# permute(t19, dims=(0, 1)) 과 같다. 0, 1차원을 바꾼다는 뜻이다.\n",
    "print(t22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "01a25c67-631a-4e57-bf29-c0fc17eed16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n"
     ]
    }
   ],
   "source": [
    "t23 = torch.t(t19)\n",
    "# 2차원 텐서에서만 사용 가능하다.\n",
    "print(t23)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cca60e-2326-4c66-b0fa-7ae7c25ef590",
   "metadata": {},
   "source": [
    "## l_tensor_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c5063a68-deda-43ec-a5f5-35031fbf01b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4160dfc0-54c7-4ccb-99a4-e86e764b6ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6, 3])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.zeros([2, 1, 3])\n",
    "t2 = torch.zeros([2, 3, 3])\n",
    "t3 = torch.zeros([2, 2, 3])\n",
    "t4 = torch.cat([t1, t2, t3], dim=1) \n",
    "# torch.cat(tensors, dim)\n",
    "# 여러 텐서를 지정한 차원을 따라 이어붙이는(concatenate)함수\n",
    "# 붙이는 차원(dim)만 은 달라도 됨\n",
    "# 나머지 모든 차원은 크기가 같아야함\n",
    "print(t4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6ced3f08-1257-48fc-bbab-22f085350b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7])\n"
     ]
    }
   ],
   "source": [
    "t5 = torch.arange(0, 3)\n",
    "t6 = torch.arange(3, 8)\n",
    "\n",
    "t7 = torch.cat((t5, t6), dim=0)  # t5뒤에 t6를 이어 붙인다\n",
    "print(t7.shape)\n",
    "print(t7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2ae39d16-7bb0-402e-9736-0fbf2e0baaab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3])\n",
      "tensor([[ 0,  1,  2],\n",
      "        [ 3,  4,  5],\n",
      "        [ 6,  7,  8],\n",
      "        [ 9, 10, 11]])\n"
     ]
    }
   ],
   "source": [
    "t8 = torch.arange(0, 6).reshape(2, 3)\n",
    "t9 = torch.arange(6, 12).reshape(2, 3)\n",
    "\n",
    "t10 = torch.cat((t8, t9), dim=0)  # 2차원 텐서 병합으로써 dim=0으로 행방향으로 쌓는다\n",
    "print(t10.size())\n",
    "print(t10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d7dbe887-50ff-4e85-adca-106a991410c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6])\n",
      "tensor([[ 0,  1,  2,  6,  7,  8],\n",
      "        [ 3,  4,  5,  9, 10, 11]])\n"
     ]
    }
   ],
   "source": [
    "t11 = torch.cat((t8, t9), dim=1)  # 2차원 텐서 병합으로써 dim=1으로 열방향으로 쌓는다\n",
    "print(t11.size())\n",
    "print(t11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e026a6a3-c466-4757-96b4-156d6357850a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 3])\n",
      "tensor([[ 0,  1,  2],\n",
      "        [ 3,  4,  5],\n",
      "        [ 6,  7,  8],\n",
      "        [ 9, 10, 11],\n",
      "        [12, 13, 14],\n",
      "        [15, 16, 17]])\n"
     ]
    }
   ],
   "source": [
    "t12 = torch.arange(0, 6).reshape(2, 3)\n",
    "t13 = torch.arange(6, 12).reshape(2, 3)\n",
    "t14 = torch.arange(12, 18).reshape(2, 3)\n",
    "\n",
    "t15 = torch.cat((t12, t13, t14), dim=0)  # dim = 0이므로 행방향으로 쌓는다\n",
    "print(t15.size())\n",
    "print(t15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8c5eae73-58b3-4011-a206-ff110f439395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 9])\n",
      "tensor([[ 0,  1,  2,  6,  7,  8, 12, 13, 14],\n",
      "        [ 3,  4,  5,  9, 10, 11, 15, 16, 17]])\n"
     ]
    }
   ],
   "source": [
    "t16 = torch.cat((t12, t13, t14), dim=1)  # dim = 1이므로 열방향으로 쌓는다\n",
    "print(t16.size())\n",
    "print(t16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6d6935c5-db91-4d13-817e-d27d54d8402b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3])\n",
      "tensor([[[ 0,  1,  2],\n",
      "         [ 3,  4,  5]],\n",
      "\n",
      "        [[ 6,  7,  8],\n",
      "         [ 9, 10, 11]]])\n"
     ]
    }
   ],
   "source": [
    "t17 = torch.arange(0, 6).reshape(1, 2, 3)\n",
    "t18 = torch.arange(6, 12).reshape(1, 2, 3)\n",
    "\n",
    "t19 = torch.cat((t17, t18), dim=0)  # dim=0이므로 0차원만 더하여 2행3열이 두개가 된다.\n",
    "print(t19.size())\n",
    "print(t19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c82c7570-f43b-4ab5-a116-223c78a0d056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 3])\n",
      "tensor([[[ 0,  1,  2],\n",
      "         [ 3,  4,  5],\n",
      "         [ 6,  7,  8],\n",
      "         [ 9, 10, 11]]])\n"
     ]
    }
   ],
   "source": [
    "t20 = torch.cat((t17, t18), dim=1)  # dim=1이므로 1차원이 더해져 4행이 된다\n",
    "print(t20.size())\n",
    "print(t20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ddf4655c-038c-4c36-af84-cdf3241c1526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 6])\n",
      "tensor([[[ 0,  1,  2,  6,  7,  8],\n",
      "         [ 3,  4,  5,  9, 10, 11]]])\n"
     ]
    }
   ],
   "source": [
    "t21 = torch.cat((t17, t18), dim=2)  # dim=2이므로 2차원이 더해져서 총 6열이 된다\n",
    "print(t21.size())\n",
    "print(t21)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c65a472-c87b-4d45-9be0-b8b797593d1b",
   "metadata": {},
   "source": [
    "## m_tensor_stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5f9b1506-1e5a-42c9-ac08-ba465c375222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6f8b5b81-5fce-4066-b2bf-8a0e2f413dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3]) True\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.tensor([[1, 2, 3], [4, 5, 6]])  \n",
    "t2 = torch.tensor([[7, 8, 9], [10, 11, 12]])\n",
    "\n",
    "t3 = torch.stack([t1, t2], dim=0)  \n",
    "# 여러 텐서를 지정된(dim=0)차원에 새로운 차원으로 쌓아 올리는 함수\n",
    "t4 = torch.cat([t1.unsqueeze(dim=0), t2.unsqueeze(dim=0)], dim=0)  \n",
    "# torch.stack으로 만든 shape과 동일한 결과를 만들기위해 unsqueeze(dim=0)으로 차원생성후 concat\n",
    "print(t3.shape, t3.equal(t4))  # t3.equal(t4)는 t3와 t4의 shape이 같은지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "be635b09-6a01-4176-815d-d0a4aa6b0b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3]) True\n"
     ]
    }
   ],
   "source": [
    "t5 = torch.stack([t1, t2], dim=1)\n",
    "t6 = torch.cat([t1.unsqueeze(dim=1), t2.unsqueeze(dim=1)], dim=1) \n",
    "# dim=1에 차원이 추가됨\n",
    "# 같은 행끼리 묶어서 나란히 들어간다\n",
    "print(t5.shape, t5.equal(t6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8dec7139-cfc8-49ec-96c7-10f2dc7048b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1,  2,  3],\n",
      "         [ 7,  8,  9]],\n",
      "\n",
      "        [[ 4,  5,  6],\n",
      "         [10, 11, 12]]])\n"
     ]
    }
   ],
   "source": [
    "# (추가) t5의 결과를 보기위함\n",
    "print(t5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "261aeb05-f6d5-4294-8825-f42ec6bdb010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 2]) True\n"
     ]
    }
   ],
   "source": [
    "t7 = torch.stack([t1, t2], dim=2)\n",
    "t8 = torch.cat([t1.unsqueeze(dim=2), t2.unsqueeze(dim=2)], dim=2)  \n",
    "# dim=2 위치에 새로운 차원을 추가하는것이다\n",
    "# stack하는 방법과 unsqueeze하는 두가지 방법이 있다. 결과는 동일다다\n",
    "print(t7.shape, t7.equal(t8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4dfe5694-cb45-4a61-8206-b83001624117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3]) torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "t9 = torch.arange(0, 3)\n",
    "t10 = torch.arange(3, 6)\n",
    "# 각각 size가 3인 텐서를 만든다\n",
    "print(t9.size(), t10.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "abace253-7357-4ff9-be0f-e61129f768bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n"
     ]
    }
   ],
   "source": [
    "t11 = torch.stack((t9, t10), dim=0)  # dim 0 위치에 새로운 차원을 추가한다\n",
    "print(t11.size())\n",
    "print(t11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "847c1b98-5247-4bc2-84b8-1c023e317696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "t12 = torch.cat((t9.unsqueeze(0), t10.unsqueeze(0)), dim=0) # 위의 예제와 동일한 결과이다\n",
    "print(t11.equal(t12))  # equal로 shape이 동일한지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ba28420e-e893-4a9c-b4d1-d7cb7676153b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2])\n",
      "tensor([[0, 3],\n",
      "        [1, 4],\n",
      "        [2, 5]])\n"
     ]
    }
   ],
   "source": [
    "t13 = torch.stack((t9, t10), dim=1)  # dim 0 위치에 새로운 차원을 추가한다\n",
    "print(t13.size())\n",
    "print(t13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c728da72-1bc6-4a95-aa90-428c760e4fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "t14 = torch.cat((t9.unsqueeze(1), t10.unsqueeze(1)), dim=1) # 위의 예제와 동일한 결과이다\n",
    "print(t13.equal(t14))  # equal로 shape이 동일한지 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9529dca7-f783-4df5-990f-d3e0bc21af12",
   "metadata": {},
   "source": [
    "## n_tensor_vstack_hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ed9b42a1-40cd-47b5-b371-9ef78073722a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6cd0e45d-fba8-4147-bbf4-2f6d9d13878d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.tensor([1, 2, 3])\n",
    "t2 = torch.tensor([4, 5, 6])\n",
    "t3 = torch.vstack((t1, t2))   \n",
    "# dim = 0을 기준으로 쌓는다\n",
    "# torch.vstack(tensors) == torch.cat(tensors, dim=0)\n",
    "# 즉, 예제는 2D 텐서이므로 행을 기준으로 쌓는다.\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "868250d6-23f0-4f0f-8fa2-80f7c49e6581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4],\n",
      "        [5],\n",
      "        [6]])\n"
     ]
    }
   ],
   "source": [
    "t4 = torch.tensor([[1], [2], [3]])\n",
    "t5 = torch.tensor([[4], [5], [6]])\n",
    "t6 = torch.vstack((t4, t5)) \n",
    "# dim = 0을 기준으로 쌓는다\n",
    "# 즉, 예제는 2D 텐서이므로 행을 기준으로 쌓는다.\n",
    "print(t6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2a563b15-5953-4843-a32b-61d7ee3271f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3])\n",
      "torch.Size([2, 2, 3])\n",
      "torch.Size([4, 2, 3])\n",
      "tensor([[[ 1,  2,  3],\n",
      "         [ 4,  5,  6]],\n",
      "\n",
      "        [[ 7,  8,  9],\n",
      "         [10, 11, 12]],\n",
      "\n",
      "        [[13, 14, 15],\n",
      "         [16, 17, 18]],\n",
      "\n",
      "        [[19, 20, 21],\n",
      "         [22, 23, 24]]])\n"
     ]
    }
   ],
   "source": [
    "t7 = torch.tensor([\n",
    "    [[1, 2, 3], [4, 5, 6]],\n",
    "    [[7, 8, 9], [10, 11, 12]]\n",
    "])\n",
    "print(t7.shape)\n",
    "\n",
    "t8 = torch.tensor([\n",
    "  [[13, 14, 15], [16, 17, 18]],\n",
    "  [[19, 20, 21], [22, 23, 24]]\n",
    "])\n",
    "print(t8.shape)\n",
    "\n",
    "t9 = torch.vstack([t7, t8])  # dim=0을 기준으로 쌓으므로 채널축으로 쌓인다.\n",
    "print(t9.shape)\n",
    "print(t9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "82be547b-1fd5-430f-8a31-cae94ebb0c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5, 6])\n"
     ]
    }
   ],
   "source": [
    "t10 = torch.tensor([1, 2, 3])\n",
    "t11 = torch.tensor([4, 5, 6])\n",
    "t12 = torch.hstack((t10, t11))\n",
    "# dim = 1을 기준으로 쌓는다\n",
    "# torch.hstack(tensors) == torch.cat(tensors, dim=1)\n",
    "print(t12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9860337f-4bff-49d1-b0aa-c53b2b195aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n"
     ]
    }
   ],
   "source": [
    "t13 = torch.tensor([[1], [2], [3]])\n",
    "t14 = torch.tensor([[4], [5], [6]])\n",
    "t15 = torch.hstack((t13, t14))\n",
    "print(t15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1f2b3a3c-5d81-4b5a-9230-a00588bcfbf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3])\n",
      "torch.Size([2, 2, 3])\n",
      "torch.Size([2, 4, 3])\n",
      "tensor([[[ 1,  2,  3],\n",
      "         [ 4,  5,  6],\n",
      "         [13, 14, 15],\n",
      "         [16, 17, 18]],\n",
      "\n",
      "        [[ 7,  8,  9],\n",
      "         [10, 11, 12],\n",
      "         [19, 20, 21],\n",
      "         [22, 23, 24]]])\n"
     ]
    }
   ],
   "source": [
    "t16 = torch.tensor([\n",
    "  [[1, 2, 3], [4, 5, 6]],\n",
    "  [[7, 8, 9], [10, 11, 12]]\n",
    "])\n",
    "print(t16.shape)\n",
    "\n",
    "t17 = torch.tensor([\n",
    "  [[13, 14, 15], [16, 17, 18]],\n",
    "  [[19, 20, 21], [22, 23, 24]]\n",
    "])\n",
    "print(t17.shape)\n",
    "\n",
    "t18 = torch.hstack([t16, t17])  # dim = 1을 기준으로 쌓여서 hstack결과 shape이 2, 4, 3이 된다\n",
    "print(t18.shape)\n",
    "print(t18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc9873e-7062-4564-99d1-6c40a0e105bb",
   "metadata": {},
   "source": [
    "## 숙제 후기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b88fbe13-fb51-43f6-99b3-2943c79210fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI 에 관심이 생겨서 3학년 1학기부터 혼자 딥러닝 예습을 진행했었습니다.\n",
    "    \n",
    "# 미리 예습을 진행한 탓에 진도를 놓치지 않고 잘 따라갈 수 있었으며, \n",
    "# 제가 부족했던 부분에 대해 더 깊이 공부할 수 있었습니다.\n",
    "    \n",
    "# 특히 hw_01과제는 구현할때 굉장이 basic한 부분이므로 매우 중요하다는 것을 알고 있었습니다.\n",
    "\n",
    "# 따라서 하나하나 타이핑하며 아는내용은 다시한번 복습하고 부족했던 부분은 더 확실히 짚고 넘어갔습니다.\n",
    "# hw_01과제에서 특히 어려웠던 부분은 stack이었습니다. 차원이 변하여 텐서의 구조가 변하는데,\n",
    "# 저는 이것을 시각화 하여 보고싶었습니다.\n",
    "\n",
    "# 따라서 1차원 2차원 3차원은 shape의 변화에따라 텐서가 어떻게 변화는지 직접 생각해보며 그려봤지만\n",
    "# 4차원부터는 매우 어려웠습니다.\n",
    "    \n",
    "# 단순히 shape이 변한다고 생각하고 넘어갈 수 있지만 저는 이것을 직접 변한걸 생각해보고 넘어가는것이\n",
    "# 더 이해가 잘 될 것이라고 판단하였기 떄문에 이렇게 해보았습니다.\n",
    "\n",
    "# 4차원부터는 직접 그리는것이 어려웠지만 이과정을 겪으므로써 확실하게 stack이 어떻게 동작하는지 알 수 있게 되었습니다.\n",
    "# 예습하며 진행해볼때 텐서의 구조와 shape의 중요성을 굉장히 뼈저리게 느꼇던 저는 이번과제를 되게 열심히 하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c3a442-c665-46a1-9d12-f37442417c60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
